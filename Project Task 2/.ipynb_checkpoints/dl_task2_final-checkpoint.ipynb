{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71489d92",
   "metadata": {
    "id": "71489d92"
   },
   "source": [
    "# **Project Task 2**\n",
    "\n",
    "**Akshay Shukla - 2022A7PS0087P**\n",
    "\n",
    "**Ishaan Kale - 2022A7PS0084P**\n",
    "\n",
    "**Siddhartha Gotur - 2022A7PS0070P**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566bfd4c",
   "metadata": {
    "id": "566bfd4c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4AtEyfl3vm_Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AtEyfl3vm_Q",
    "outputId": "980b388f-06b2-4ac2-c8ca-3b93065a9d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "_F_ZekH9qnX2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_F_ZekH9qnX2",
    "outputId": "2c2a4ebf-cf69-4ab1-e79d-d88b5885348d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /content/flower_dataset.zip, /content/flower_dataset.zip.zip or /content/flower_dataset.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "!unzip /content/flower_dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fce3e90",
   "metadata": {
    "id": "9fce3e90"
   },
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db4d452",
   "metadata": {
    "id": "6db4d452"
   },
   "outputs": [],
   "source": [
    "train_dir = \"./train_data\"\n",
    "val_dir = \"./val_data\"\n",
    "train_labels_path = \"./train_labels.txt\"\n",
    "val_labels_path = \"./val_labels.txt\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f3bdce0",
   "metadata": {
    "id": "8f3bdce0"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/flower_dataset/train_labels.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(line\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n\u001b[0;32m----> 6\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m val_labels \u001b[38;5;241m=\u001b[39m load_labels(val_labels_path)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get file paths\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m, in \u001b[0;36mload_labels\u001b[0;34m(labels_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_labels\u001b[39m(labels_path):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m         labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(line\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mreadlines()]\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/flower_dataset/train_labels.txt'"
     ]
    }
   ],
   "source": [
    "def load_labels(labels_path):\n",
    "    with open(labels_path, 'r') as f:\n",
    "        labels = [int(line.strip()) for line in f.readlines()]\n",
    "    return labels\n",
    "\n",
    "train_labels = load_labels(train_labels_path)\n",
    "val_labels = load_labels(val_labels_path)\n",
    "\n",
    "# Get file paths\n",
    "train_images = sorted([os.path.join(train_dir, img) for img in os.listdir(train_dir) if img.endswith('.jpg')])\n",
    "val_images = sorted([os.path.join(val_dir, img) for img in os.listdir(val_dir) if img.endswith('.jpg')])\n",
    "\n",
    "# Ensure the number of images matches the number of labels\n",
    "assert len(train_images) == len(train_labels), \"Mismatch in training images and labels!\"\n",
    "assert len(val_images) == len(val_labels), \"Mismatch in validation images and labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8903ebae",
   "metadata": {
    "id": "8903ebae"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275affac",
   "metadata": {
    "id": "275affac"
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, IMG_SIZE)\n",
    "    IMAGENET_MEAN = [123.68, 116.779, 103.939]\n",
    "    IMAGENET_STD = [58.393, 57.12, 57.375]\n",
    "    mean = tf.constant(IMAGENET_MEAN, dtype=tf.float32)\n",
    "    std = tf.constant(IMAGENET_STD, dtype=tf.float32)\n",
    "    image = (image - mean) / std\n",
    "    return image, tf.one_hot(label, 60)\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_ds = val_ds.map(preprocess_image).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad301d",
   "metadata": {
    "id": "ebad301d"
   },
   "source": [
    "**Data Visualisation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc7bddf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "2dc7bddf",
    "outputId": "0d13f5ab-a47b-4df7-b233-9276ebd09f61"
   },
   "outputs": [],
   "source": [
    "def visualize_data(images, labels, label_mapping, num_samples=9):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    indices = tf.random.shuffle(tf.range(len(images)))[:num_samples]\n",
    "    for i, idx in enumerate(indices):\n",
    "        img = tf.io.read_file(images[idx])\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = img / 255.0  # Normalize\n",
    "\n",
    "        plt.subplot(int(num_samples**0.5), int(num_samples**0.5), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(label_mapping[labels[idx]])  # Directly use labels[idx] instead of .numpy()\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create label mapping for visualization\n",
    "unique_labels = sorted(set(train_labels))  # Get unique class labels\n",
    "label_mapping = {i: f\"Class {i}\" for i in unique_labels}\n",
    "\n",
    "print(\"Visualizing training data...\")\n",
    "visualize_data(train_images, train_labels, label_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea794ff",
   "metadata": {
    "id": "aea794ff"
   },
   "source": [
    "**Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aad097",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d2aad097",
    "outputId": "68c72347-4a93-4077-9948-6c9ddc4830dc"
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# base_model.trainable = False  # Freeze the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation='leaky_relu',kernel_regularizer=l2(0.01)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(60, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e88553",
   "metadata": {
    "id": "f1e88553"
   },
   "source": [
    "**Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aca9dde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aca9dde",
    "outputId": "45b98cf7-2e0f-439d-e7d7-9a1715e86a9e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=10,\n",
    "                    verbose=1)\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=20,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4949af0",
   "metadata": {
    "id": "b4949af0"
   },
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "model.save_weights(\"flower_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc63b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "9dfc63b1",
    "outputId": "5e614ad6-5dc2-4a24-c063-f21a8395b014"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation loss/accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss vs Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Accuracy vs Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3910c84",
   "metadata": {
    "id": "e3910c84"
   },
   "source": [
    "**Function for testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cxn4UIHMyGO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cxn4UIHMyGO",
    "outputId": "2bc3512f-3837-4232-fdd6-abd4c6da5b50"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#Model architecture\n",
    "def create_model():\n",
    "    base_model = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256, activation='leaky_relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(60, activation='softmax')\n",
    "    ])\n",
    "    model.build(input_shape=(None, 224, 224, 3))\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the model weights\n",
    "model = create_model()\n",
    "model.load_weights(\"./flower_model.weights.h5\")\n",
    "\n",
    "# Load and preprocess validation data\n",
    "def preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    IMAGENET_MEAN = [123.68, 116.779, 103.939]\n",
    "    IMAGENET_STD = [58.393, 57.12, 57.375]\n",
    "    mean = tf.constant(IMAGENET_MEAN, dtype=tf.float32)\n",
    "    std = tf.constant(IMAGENET_STD, dtype=tf.float32)\n",
    "    image = (image - mean) / std\n",
    "    return image, tf.one_hot(label, 60)\n",
    "\n",
    "test_dir = \"./val_data\"  # Replace with actual validation data directory\n",
    "test_labels_path = \"./val_labels.txt\"  # Replace with actual validation labels path\n",
    "\n",
    "test_images = sorted([os.path.join(test_dir, img) for img in os.listdir(test_dir) if img.endswith('.jpg')])\n",
    "with open(test_labels_path, 'r') as f:\n",
    "    test_labels = [int(line.strip()) for line in f.readlines()]\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.map(lambda img, label: (preprocess_image(img, label))).batch(32) # Assuming BATCH_SIZE is 32\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W0JCMHCuNyGj",
   "metadata": {
    "id": "W0JCMHCuNyGj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
